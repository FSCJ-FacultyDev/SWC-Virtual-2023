{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hydraulic-beijing",
   "metadata": {},
   "source": [
    "# Anomaly Detection in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-client",
   "metadata": {},
   "source": [
    "This notebook covers the material in the AI+ Training course on an introduction to fraud and anomaly detection. It goes through three main modules as follows:\n",
    "\n",
    "1. Data Preparation\n",
    "2. Probability and Statistical Approaches\n",
    "3. Machine Learning Approaches\n",
    "\n",
    "The following code loads all the necessary packages and libraries for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modified-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "explicit-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from scipy) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "scenic-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: distfit in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (1.6.10)\n",
      "Requirement already satisfied: packaging in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (23.1)\n",
      "Requirement already satisfied: matplotlib>=3.5.2 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (3.7.1)\n",
      "Requirement already satisfied: numpy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.24.3)\n",
      "Requirement already satisfied: pandas in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (2.0.1)\n",
      "Requirement already satisfied: tqdm in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (4.65.0)\n",
      "Requirement already satisfied: statsmodels in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (0.14.0)\n",
      "Requirement already satisfied: scipy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.10.1)\n",
      "Requirement already satisfied: pypickle in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.1.0)\n",
      "Requirement already satisfied: colourmap>=1.1.10 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.1.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->distfit) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->distfit) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from statsmodels->distfit) (0.5.3)\n",
      "Requirement already satisfied: colorama in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from tqdm->distfit) (0.4.6)\n",
      "Requirement already satisfied: six in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from patsy>=0.5.2->statsmodels->distfit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install distfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "processed-textbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: benfordslaw in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (3.7.1)\n",
      "Requirement already satisfied: numpy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (1.24.3)\n",
      "Requirement already satisfied: scipy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (1.10.1)\n",
      "Requirement already satisfied: pandas in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (2.0.1)\n",
      "Requirement already satisfied: wget in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->benfordslaw) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->benfordslaw) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->benfordslaw) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install benfordslaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "changing-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "raising-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db909375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: distfit in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (1.6.10)\n",
      "Requirement already satisfied: packaging in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (23.1)\n",
      "Requirement already satisfied: matplotlib>=3.5.2 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (3.7.1)\n",
      "Requirement already satisfied: numpy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.24.3)\n",
      "Requirement already satisfied: pandas in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (2.0.1)\n",
      "Requirement already satisfied: tqdm in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (4.65.0)\n",
      "Requirement already satisfied: statsmodels in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (0.14.0)\n",
      "Requirement already satisfied: scipy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.10.1)\n",
      "Requirement already satisfied: pypickle in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.1.0)\n",
      "Requirement already satisfied: colourmap>=1.1.10 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from distfit) (1.1.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib>=3.5.2->distfit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->distfit) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->distfit) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from statsmodels->distfit) (0.5.3)\n",
      "Requirement already satisfied: colorama in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from tqdm->distfit) (0.4.6)\n",
      "Requirement already satisfied: six in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from patsy>=0.5.2->statsmodels->distfit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install distfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60d38fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: benfordslaw in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (3.7.1)\n",
      "Requirement already satisfied: numpy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (1.24.3)\n",
      "Requirement already satisfied: scipy in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (1.10.1)\n",
      "Requirement already satisfied: pandas in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (2.0.1)\n",
      "Requirement already satisfied: wget in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from benfordslaw) (3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from matplotlib->benfordslaw) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->benfordslaw) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from pandas->benfordslaw) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\fscj\\odsc\\odsc-2023\\fraud-and-anomaly-detection-230509-part1\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->benfordslaw) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install benfordslaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71b4e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pacific-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from distfit import distfit\n",
    "from benfordslaw import benfordslaw\n",
    "from sklearn.covariance import MinCovDet\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-tolerance",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-matthew",
   "metadata": {},
   "source": [
    "This module details the area of data preparation for good anomaly detection. Anomaly detection is only as good as the data and the features that you have to detect anomalies. This module covers four main concepts in data preparation:\n",
    "\n",
    "1. Feature Engineering\n",
    "2. Recency and Frequency\n",
    "3. Periodic Means\n",
    "4. Categorical Feature Engineering\n",
    "\n",
    "Let's load the dataset we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accepting-watershed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward_R</th>\n",
       "      <th>Reward_A</th>\n",
       "      <th>Cov_Limit</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/10/1977</td>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>IN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>61000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/31/2005</td>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>CL</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>61000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/17/2006</td>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>265.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/15/1998</td>\n",
       "      <td>PSX000100010</td>\n",
       "      <td>IN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>29000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/7/1961</td>\n",
       "      <td>PSX000100013</td>\n",
       "      <td>IN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Cust_ID Transaction Type  Reward_R  Reward_A  Cov_Limit   \n",
       "0   9/10/1977  PSX000100006          IN    T       NaN       NaN    50000.0  \\\n",
       "1  12/31/2005  PSX000100006          CL    T       NaN       NaN    50000.0   \n",
       "2   1/17/2006  PSX000100006          RE    T     265.0   50000.0        NaN   \n",
       "3  12/15/1998  PSX000100010          IN    T       NaN       NaN   100000.0   \n",
       "4    6/7/1961  PSX000100013          IN    V       NaN       NaN   100000.0   \n",
       "\n",
       "    Income  \n",
       "0  61000.0  \n",
       "1  61000.0  \n",
       "2      NaN  \n",
       "3  29000.0  \n",
       "4  48000.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins = pd.read_csv(\"transactions_ins.csv\")\n",
    "\n",
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beautiful-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward_R</th>\n",
       "      <th>Reward_A</th>\n",
       "      <th>Cov_Limit</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278877</td>\n",
       "      <td>278877</td>\n",
       "      <td>278877</td>\n",
       "      <td>278877</td>\n",
       "      <td>44488.000000</td>\n",
       "      <td>4.448800e+04</td>\n",
       "      <td>2.343890e+05</td>\n",
       "      <td>234389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>23165</td>\n",
       "      <td>121191</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>9/15/2010</td>\n",
       "      <td>PSX000704539</td>\n",
       "      <td>IN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>121191</td>\n",
       "      <td>139958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.732602</td>\n",
       "      <td>2.247246e+05</td>\n",
       "      <td>2.057786e+05</td>\n",
       "      <td>53363.899594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.895957</td>\n",
       "      <td>2.284420e+05</td>\n",
       "      <td>1.984034e+05</td>\n",
       "      <td>25199.547677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>34422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>68026.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>2.700000e+06</td>\n",
       "      <td>2.700000e+06</td>\n",
       "      <td>232392.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       Cust_ID Transaction    Type      Reward_R   \n",
       "count      278877        278877      278877  278877  44488.000000  \\\n",
       "unique      23165        121191           4       3           NaN   \n",
       "top     9/15/2010  PSX000704539          IN       T           NaN   \n",
       "freq           44            21      121191  139958           NaN   \n",
       "mean          NaN           NaN         NaN     NaN    315.732602   \n",
       "std           NaN           NaN         NaN     NaN    126.895957   \n",
       "min           NaN           NaN         NaN     NaN    100.000000   \n",
       "25%           NaN           NaN         NaN     NaN    207.000000   \n",
       "50%           NaN           NaN         NaN     NaN    314.000000   \n",
       "75%           NaN           NaN         NaN     NaN    421.000000   \n",
       "max           NaN           NaN         NaN     NaN    579.000000   \n",
       "\n",
       "            Reward_A     Cov_Limit         Income  \n",
       "count   4.448800e+04  2.343890e+05  234389.000000  \n",
       "unique           NaN           NaN            NaN  \n",
       "top              NaN           NaN            NaN  \n",
       "freq             NaN           NaN            NaN  \n",
       "mean    2.247246e+05  2.057786e+05   53363.899594  \n",
       "std     2.284420e+05  1.984034e+05   25199.547677  \n",
       "min     0.000000e+00  5.000000e+04   15000.000000  \n",
       "25%     1.000000e+05  1.000000e+05   34422.000000  \n",
       "50%     1.500000e+05  1.500000e+05   50000.000000  \n",
       "75%     3.000000e+05  2.500000e+05   68026.000000  \n",
       "max     2.700000e+06  2.700000e+06  232392.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pleasant-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins['Date'] = pd.to_datetime(ins['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-performance",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-reputation",
   "metadata": {},
   "source": [
    "The concept of feature engineering is vitally important to anomaly detection. In my personal experience, the best features aren't just automatically generated by a computer, but thought up by a knowledgable individual working on the problem. \n",
    "\n",
    "We are going to role up the transactions to be one per individual. Here are some basic features when rolling up our transactions that might be important when discovering fraud:\n",
    "- Final income\n",
    "- Time between claim and reward\n",
    "- Coverage limit to income ratio at claim\n",
    "\n",
    "Think of some more of your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-ranking",
   "metadata": {},
   "source": [
    "Let's create final income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "political-group",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Cov_Limit</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>61000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PSX000100013</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PSX000100073</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PSX000100081</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>69000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PSX000100122</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PSX000100146</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>38000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PSX000100231</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>79155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PSX000100236</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>54738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>PSX000100286</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>95973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>PSX00010030</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>37725.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cust_ID  Cov_Limit    Income\n",
       "1   PSX000100006    50000.0   61000.0\n",
       "5   PSX000100013   100000.0   48000.0\n",
       "14  PSX000100073   100000.0   35000.0\n",
       "18  PSX000100081    50000.0   69000.0\n",
       "24  PSX000100122   150000.0  105000.0\n",
       "31  PSX000100146   100000.0   38000.0\n",
       "50  PSX000100231   400000.0   79155.0\n",
       "56  PSX000100236   250000.0   54738.0\n",
       "62  PSX000100286   150000.0   95973.0\n",
       "67   PSX00010030   350000.0   37725.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_income = ins[ins['Transaction'] == 'CL']\n",
    "\n",
    "ins_income = ins_income[['Cust_ID', 'Cov_Limit', 'Income']]\n",
    "\n",
    "ins_income.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-madrid",
   "metadata": {},
   "source": [
    "Now, let's create time in between claim and reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "african-prescription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward_R</th>\n",
       "      <th>Reward_A</th>\n",
       "      <th>Cov_Limit</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>CL</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>61000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>265.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-06-12</td>\n",
       "      <td>PSX000100013</td>\n",
       "      <td>CL</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-07-11</td>\n",
       "      <td>PSX000100013</td>\n",
       "      <td>RE</td>\n",
       "      <td>V</td>\n",
       "      <td>265.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004-01-21</td>\n",
       "      <td>PSX000100073</td>\n",
       "      <td>CL</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004-02-14</td>\n",
       "      <td>PSX000100073</td>\n",
       "      <td>RE</td>\n",
       "      <td>V</td>\n",
       "      <td>450.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009-06-28</td>\n",
       "      <td>PSX000100081</td>\n",
       "      <td>CL</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>69000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009-07-26</td>\n",
       "      <td>PSX000100081</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1991-08-23</td>\n",
       "      <td>PSX000100122</td>\n",
       "      <td>CL</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1991-09-08</td>\n",
       "      <td>PSX000100122</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>200.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Cust_ID Transaction Type  Reward_R  Reward_A  Cov_Limit   \n",
       "1  2005-12-31  PSX000100006          CL    T       NaN       NaN    50000.0  \\\n",
       "2  2006-01-17  PSX000100006          RE    T     265.0   50000.0        NaN   \n",
       "5  2001-06-12  PSX000100013          CL    V       NaN       NaN   100000.0   \n",
       "6  2001-07-11  PSX000100013          RE    V     265.0  100000.0        NaN   \n",
       "14 2004-01-21  PSX000100073          CL    V       NaN       NaN   100000.0   \n",
       "15 2004-02-14  PSX000100073          RE    V     450.0  100000.0        NaN   \n",
       "18 2009-06-28  PSX000100081          CL    T       NaN       NaN    50000.0   \n",
       "19 2009-07-26  PSX000100081          RE    T     543.0       0.0        NaN   \n",
       "24 1991-08-23  PSX000100122          CL    T       NaN       NaN   150000.0   \n",
       "25 1991-09-08  PSX000100122          RE    T     200.0  150000.0        NaN   \n",
       "\n",
       "      Income  \n",
       "1    61000.0  \n",
       "2        NaN  \n",
       "5    48000.0  \n",
       "6        NaN  \n",
       "14   35000.0  \n",
       "15       NaN  \n",
       "18   69000.0  \n",
       "19       NaN  \n",
       "24  105000.0  \n",
       "25       NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_time = ins[(ins['Transaction'] == 'CL') | (ins['Transaction'] == 'RE')]\n",
    "\n",
    "ins_time.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "attended-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward_R</th>\n",
       "      <th>Reward_A</th>\n",
       "      <th>Cov_Limit</th>\n",
       "      <th>Income</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>265.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-07-11</td>\n",
       "      <td>PSX000100013</td>\n",
       "      <td>RE</td>\n",
       "      <td>V</td>\n",
       "      <td>265.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1651 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004-02-14</td>\n",
       "      <td>PSX000100073</td>\n",
       "      <td>RE</td>\n",
       "      <td>V</td>\n",
       "      <td>450.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>948 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009-07-26</td>\n",
       "      <td>PSX000100081</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1991-09-08</td>\n",
       "      <td>PSX000100122</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>200.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6531 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2009-04-21</td>\n",
       "      <td>PSX000100146</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>275.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6435 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2008-05-05</td>\n",
       "      <td>PSX000100231</td>\n",
       "      <td>RE</td>\n",
       "      <td>V</td>\n",
       "      <td>405.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-351 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1970-10-06</td>\n",
       "      <td>PSX000100236</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>469.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13726 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2003-03-20</td>\n",
       "      <td>PSX000100286</td>\n",
       "      <td>RE</td>\n",
       "      <td>V</td>\n",
       "      <td>337.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11853 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1980-01-09</td>\n",
       "      <td>PSX00010030</td>\n",
       "      <td>RE</td>\n",
       "      <td>T</td>\n",
       "      <td>377.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8471 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Cust_ID Transaction Type  Reward_R  Reward_A  Cov_Limit   \n",
       "2  2006-01-17  PSX000100006          RE    T     265.0   50000.0        NaN  \\\n",
       "6  2001-07-11  PSX000100013          RE    V     265.0  100000.0        NaN   \n",
       "15 2004-02-14  PSX000100073          RE    V     450.0  100000.0        NaN   \n",
       "19 2009-07-26  PSX000100081          RE    T     543.0       0.0        NaN   \n",
       "25 1991-09-08  PSX000100122          RE    T     200.0  150000.0        NaN   \n",
       "32 2009-04-21  PSX000100146          RE    T     275.0  100000.0        NaN   \n",
       "51 2008-05-05  PSX000100231          RE    V     405.0  400000.0        NaN   \n",
       "57 1970-10-06  PSX000100236          RE    T     469.0  250000.0        NaN   \n",
       "63 2003-03-20  PSX000100286          RE    V     337.0  150000.0        NaN   \n",
       "68 1980-01-09   PSX00010030          RE    T     377.0  350000.0        NaN   \n",
       "\n",
       "    Income        diff  \n",
       "2      NaN         NaT  \n",
       "6      NaN  -1651 days  \n",
       "15     NaN    948 days  \n",
       "19     NaN   1989 days  \n",
       "25     NaN  -6531 days  \n",
       "32     NaN   6435 days  \n",
       "51     NaN   -351 days  \n",
       "57     NaN -13726 days  \n",
       "63     NaN  11853 days  \n",
       "68     NaN  -8471 days  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_time['diff'] = ins_time['Date'] - ins_time['Date'].shift(1)\n",
    "\n",
    "ins_time.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "electoral-mississippi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward_R</th>\n",
       "      <th>Reward_A</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>PSX000100006</td>\n",
       "      <td>T</td>\n",
       "      <td>265.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-07-11</td>\n",
       "      <td>PSX000100013</td>\n",
       "      <td>V</td>\n",
       "      <td>265.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>-1651 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004-02-14</td>\n",
       "      <td>PSX000100073</td>\n",
       "      <td>V</td>\n",
       "      <td>450.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>948 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009-07-26</td>\n",
       "      <td>PSX000100081</td>\n",
       "      <td>T</td>\n",
       "      <td>543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1989 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1991-09-08</td>\n",
       "      <td>PSX000100122</td>\n",
       "      <td>T</td>\n",
       "      <td>200.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>-6531 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2009-04-21</td>\n",
       "      <td>PSX000100146</td>\n",
       "      <td>T</td>\n",
       "      <td>275.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>6435 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2008-05-05</td>\n",
       "      <td>PSX000100231</td>\n",
       "      <td>V</td>\n",
       "      <td>405.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>-351 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1970-10-06</td>\n",
       "      <td>PSX000100236</td>\n",
       "      <td>T</td>\n",
       "      <td>469.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>-13726 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2003-03-20</td>\n",
       "      <td>PSX000100286</td>\n",
       "      <td>V</td>\n",
       "      <td>337.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>11853 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1980-01-09</td>\n",
       "      <td>PSX00010030</td>\n",
       "      <td>T</td>\n",
       "      <td>377.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>-8471 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Cust_ID Type  Reward_R  Reward_A        diff\n",
       "2  2006-01-17  PSX000100006    T     265.0   50000.0         NaT\n",
       "6  2001-07-11  PSX000100013    V     265.0  100000.0  -1651 days\n",
       "15 2004-02-14  PSX000100073    V     450.0  100000.0    948 days\n",
       "19 2009-07-26  PSX000100081    T     543.0       0.0   1989 days\n",
       "25 1991-09-08  PSX000100122    T     200.0  150000.0  -6531 days\n",
       "32 2009-04-21  PSX000100146    T     275.0  100000.0   6435 days\n",
       "51 2008-05-05  PSX000100231    V     405.0  400000.0   -351 days\n",
       "57 1970-10-06  PSX000100236    T     469.0  250000.0 -13726 days\n",
       "63 2003-03-20  PSX000100286    V     337.0  150000.0  11853 days\n",
       "68 1980-01-09   PSX00010030    T     377.0  350000.0  -8471 days"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_time = ins_time[ins_time['Transaction'] == 'RE']\n",
    "\n",
    "ins_time = ins_time[['Date', 'Cust_ID', 'Type', 'Reward_R', 'Reward_A', 'diff']]\n",
    "\n",
    "ins_time.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-server",
   "metadata": {},
   "source": [
    "Lastly, let's combine our datasets from above and create coverage limit to income ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "analyzed-circulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward_R</th>\n",
       "      <th>Reward_A</th>\n",
       "      <th>Cov_Limit</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Cust_ID, Transaction, Type, Reward_R, Reward_A, Cov_Limit, Income]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_feat = ins_time.merge(ins_income)\n",
    "\n",
    "ins_feat.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "proper-debut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reward_R</th>\n",
       "      <th>Reward_A</th>\n",
       "      <th>Cov_Limit</th>\n",
       "      <th>Income</th>\n",
       "      <th>Cov_Income_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Cust_ID, Transaction, Type, Reward_R, Reward_A, Cov_Limit, Income, Cov_Income_Ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_feat['Cov_Income_Ratio'] = ins_feat['Cov_Limit'] / ins_feat['Income']\n",
    "\n",
    "ins_feat.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-budapest",
   "metadata": {},
   "source": [
    "### Recency and Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-ending",
   "metadata": {},
   "source": [
    "We will look at recency and frequency one at a time. Let's start with recency. For ease of application, let's use all the differences in time for all customers to build our recency exponential distribution instead of building one per customer.\n",
    "\n",
    "Specifically, we will look at recency of changes in policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_rec = ins\n",
    "\n",
    "ins_rec['diff'] = ins_rec['Date'] - ins_rec['Date'].shift(1)\n",
    "\n",
    "ins_rec = ins_rec[ins_rec['Transaction'] == 'CH']\n",
    "\n",
    "ins_rec.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rec = st.distributions.expon.fit(ins_rec['diff'].dt.days)\n",
    "\n",
    "print(exp_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_rec['rec'] = np.exp(-(1/exp_rec[1])*(ins_rec['diff'].dt.days))\n",
    "\n",
    "ins_rec.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_rec = ins_rec.groupby('Cust_ID', as_index=False)['rec'].mean()\n",
    "\n",
    "ins_rec.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-blond",
   "metadata": {},
   "source": [
    "For our data, frequency of changes in policy might also be a flag of fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_changes = ins\n",
    "\n",
    "ins_changes['T_CH'] = pd.get_dummies(ins_changes['Transaction'], prefix='T')['T_CH']\n",
    "\n",
    "ins_changes = ins_changes.groupby('Cust_ID', as_index=False)['T_CH'].sum()\n",
    "\n",
    "ins_changes.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-november",
   "metadata": {},
   "source": [
    "Let's combine these recency and frequency features into our features dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_feat = ins_feat.merge(ins_rec)\n",
    "\n",
    "ins_feat.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_feat = ins_feat.merge(ins_changes)\n",
    "\n",
    "ins_feat.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-perception",
   "metadata": {},
   "source": [
    "### Periodic Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-strand",
   "metadata": {},
   "source": [
    "Python isn't as well created for this feature as compared to R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-fortune",
   "metadata": {},
   "source": [
    "### Categorical Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-beast",
   "metadata": {},
   "source": [
    "Feature engineering doesn't stop with just continuous variables in transactional data. We need to account for categorical features as well.\n",
    "\n",
    "In our data, the reward reason (Reward_R) variable is categorical. It has numerical representations for reasons of passing that are given on the life insurance policy. Some of these reasons are approved - life insurance policy is paid out. However, not all reasons of passing are covered so the policy isn't paid out in those scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ins_feat['Reward_R']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-parallel",
   "metadata": {},
   "source": [
    "Instead of having 480 possible categories, let combine these into two groups - approved and rejected reasons - based on the reward amount. If the reward amount was 0, then the reason was not covered by the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_feat['Reward_Y'] = ins_feat['Reward_A'].apply(lambda x: 'Y' if x > 0 else 'N')\n",
    "\n",
    "ins_feat.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-policy",
   "metadata": {},
   "source": [
    "## Probability and Statistical Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-invention",
   "metadata": {},
   "source": [
    "This module details the area of probability and statistical approaches to anomaly detection. Classical probability and statistical approaches to anomaly detection are a great foundation and are still widely used and useful in detecting anomalies. This module covers four main concepts in probability and statistical approaches to anomaly detection:\n",
    "\n",
    "1. Benford's Law\n",
    "2. Z-scores and Robust Z-scores\n",
    "3. IQR Rule and It's Adjustment\n",
    "4. Mahalanobis Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-albuquerque",
   "metadata": {},
   "source": [
    "### Benford's Law"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-sound",
   "metadata": {},
   "source": [
    "We don't have addresses in our data so it makes it hard to see if someone applied for a life insurance policy using fake information. However, let's see how we would apply that to data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl = benfordslaw(alpha=0.05)\n",
    "\n",
    "results = bl.fit(ins_feat['Income'])\n",
    "\n",
    "bl.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-respondent",
   "metadata": {},
   "source": [
    "### Z-Scores and Robust Z-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-merchant",
   "metadata": {},
   "source": [
    "We want to evaluate if we have an observation far away from \"normal\" in our coverage to income ratio at time of claim. We are looking for really large life insurance coverage limits when income is not very high - a large ratio between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ins_feat['Cov_Income_Ratio'])\n",
    "plt.xlabel('Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Coverage to Income Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_feat['Z_Cov_Income_Ratio'] = abs((ins_feat['Cov_Income_Ratio'] - ins_feat['Cov_Income_Ratio'].mean())/ins_feat['Cov_Income_Ratio'].std())\n",
    "\n",
    "plt.hist(ins_feat['Z_Cov_Income_Ratio'])\n",
    "plt.xlabel('Z-Scores')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Coverage to Income Ratio Z-Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ins_feat[ins_feat['Z_Cov_Income_Ratio'] > 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-danger",
   "metadata": {},
   "source": [
    "Let's switch to using the robust z-score calculation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_feat['RZ_Cov_Income_Ratio'] = abs((ins_feat['Cov_Income_Ratio'] - ins_feat['Cov_Income_Ratio'].median())/st.median_absolute_deviation(ins_feat['Cov_Income_Ratio']))\n",
    "\n",
    "plt.hist(ins_feat['RZ_Cov_Income_Ratio'])\n",
    "plt.xlabel('Robust Z-Scores')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Coverage to Income Ratio Robust Z-Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ins_feat[ins_feat['RZ_Cov_Income_Ratio'] > 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-batman",
   "metadata": {},
   "source": [
    "### IQR Rule and It's Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-privilege",
   "metadata": {},
   "source": [
    "Another univariate approach to looking for outliers is the IQR Rule. However, the IQR Rule really works best for symmetric distributions. For our coverage limit to income ratio variable we know this isn't symmetric based on our above plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Coverage to Income Ratio')\n",
    "ax1.boxplot(ins_feat['Cov_Income_Ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-constitutional",
   "metadata": {},
   "source": [
    "### Mahalanobis Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-detective",
   "metadata": {},
   "source": [
    "When looking at two or more variables at the same time, we need to account for multiple dimensions. Mahalanobis distances are a multivariate version of the z-score. \n",
    "\n",
    "Let compare the two variables of average recency of changes in policies and frequency of these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = ins_feat['Income'], y = ins_feat['Cov_Income_Ratio'], alpha = 0.5)\n",
    "plt.xlabel('Income ($)')\n",
    "plt.ylabel('Coverage to Income Ratio')\n",
    "plt.title('Income vs. Coverage to Income Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_ellipse(x, y, ax, n_std=2.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_nstd = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "mu = ins_feat['Income'].mean(), ins_feat['Cov_Income_Ratio'].mean()\n",
    "\n",
    "ax_nstd.axvline(c='grey', lw=1)\n",
    "ax_nstd.axhline(c='grey', lw=1)\n",
    "\n",
    "x = ins_feat['Income']\n",
    "y = ins_feat['Cov_Income_Ratio']\n",
    "ax_nstd.scatter(x, y, s=0.5)\n",
    "\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=4.5, edgecolor='blue', linestyle='-')\n",
    "\n",
    "ax_nstd.scatter(mu[0], mu[1], c='red', s=3)\n",
    "ax_nstd.set_title('Income vs. Coverage to Income Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Income': ins_feat['Income'], 'CIRatio': ins_feat['Cov_Income_Ratio']}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "covMCD = MinCovDet(random_state=0).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_ellipse_r(x, y, ax, n_std=4.5, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "        \n",
    "    d = {'X': x, 'Y': y}\n",
    "    df = pd.DataFrame(data=d)\n",
    "\n",
    "    covMCD = MinCovDet(random_state=0).fit(df)\n",
    "\n",
    "    cov = covMCD.covariance_\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = covMCD.location_[0]\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = covMCD.location_[1]\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_nstd = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "mu = ins_feat['Income'].mean(), ins_feat['Cov_Income_Ratio'].mean()\n",
    "\n",
    "ax_nstd.axvline(c='grey', lw=1)\n",
    "ax_nstd.axhline(c='grey', lw=1)\n",
    "\n",
    "x = ins_feat['Income']\n",
    "y = ins_feat['Cov_Income_Ratio']\n",
    "ax_nstd.scatter(x, y, s=0.5)\n",
    "\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=4.5, edgecolor='blue', linestyle='-')\n",
    "confidence_ellipse_r(x, y, ax_nstd, n_std=4.5, edgecolor='red', linestyle='-')\n",
    "\n",
    "ax_nstd.scatter(mu[0], mu[1], c='red', s=3)\n",
    "ax_nstd.set_title('Income vs. Coverage to Income Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-transfer",
   "metadata": {},
   "source": [
    "## Machine Learning Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-ordinance",
   "metadata": {},
   "source": [
    "This module details the area of machine learning approaches to anomaly detection. With the enhancements and creation of machine learning approaches to modeling, these same techniques form the foundation of more advanced anomaly detection methods. This module covers five main concepts in machine learning approaches to anomaly detection:\n",
    "\n",
    "1. k-Nearest Neighbors (k-NN)\n",
    "2. Local Outlier Factor (LOF)\n",
    "3. Isolation Forests\n",
    "4. Classifier-Adjusted Density Estimation (CADE)\n",
    "5. One-Class Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-truck",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-connection",
   "metadata": {},
   "source": [
    "Instead of looking at more statistical approaches, we can directly look at the average distance each point is from its k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Income': ins_feat['Income'], 'CIRatio': ins_feat['Cov_Income_Ratio']}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=6, algorithm='ball_tree').fit(df)\n",
    "distances, indices = nbrs.kneighbors(df)\n",
    "\n",
    "print(distances)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nndist'] = np.mean(distances, axis = 1)\n",
    "\n",
    "plt.scatter(x = ins_feat['Income'], y = ins_feat['Cov_Income_Ratio'], alpha = 0.5, s = (df['nndist'])**(0.75))\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Coverage to Income Ratio (Thousands $)')\n",
    "plt.title('Income vs. Coverage to Income Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-circular",
   "metadata": {},
   "source": [
    "### Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-explosion",
   "metadata": {},
   "source": [
    "Let's examine more local outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Income': ins_feat['Income'], 'CIRatio': ins_feat['Cov_Income_Ratio']}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=6)\n",
    "lof.fit_predict(df)\n",
    "\n",
    "df['lof'] = -lof.negative_outlier_factor_\n",
    "\n",
    "plt.scatter(x = ins_feat['Income'], y = ins_feat['Cov_Income_Ratio'], alpha = 0.5, s = df['lof']*10)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Coverage to Income Ratio (Thousands $)')\n",
    "plt.title('Income vs. Coverage to Income Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['lof']*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-spring",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-margin",
   "metadata": {},
   "source": [
    "Instead of distance based measures, now we switch to tree based approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Income': ins_feat['Income'], 'CIRatio': ins_feat['Cov_Income_Ratio']}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "isofor = IsolationForest(random_state=0, n_estimators = 500).fit(df)\n",
    "iso = -isofor.score_samples(df)\n",
    "\n",
    "df['iso'] = iso\n",
    "df['iso2'] = ((iso - np.min(iso))/(np.max(iso) - np.min(iso))*10)**2\n",
    "\n",
    "plt.scatter(x = ins_feat['Income'], y = ins_feat['Cov_Income_Ratio'], alpha = 0.25, s = df['iso2'])\n",
    "plt.xlabel('Income ($)')\n",
    "plt.ylabel('Coverage to Income Ratio')\n",
    "plt.title('Income vs. Coverage to Income Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['iso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-origin",
   "metadata": {},
   "source": [
    "### Classifier-Adjusted Density Estimation (CADE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-dutch",
   "metadata": {},
   "source": [
    "Let's now finish off with more density based approaches to anomaly detection. Unfortunately, since CADE is so new we need to write it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Income': ins_feat['Income'], 'CIRatio': ins_feat['Cov_Income_Ratio'], 'Target': 0}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "df.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fake = {'Income': np.random.uniform(np.min(ins_feat['Income']), np.max(ins_feat['Income']), size = len(ins_feat['Income'])), \n",
    "          'CIRatio': np.random.uniform(np.min(ins_feat['Cov_Income_Ratio']), np.max(ins_feat['Cov_Income_Ratio']), \n",
    "                                       size = len(ins_feat['Cov_Income_Ratio'])),\n",
    "          'Target': 1}\n",
    "df_fake = pd.DataFrame(data=d_fake)\n",
    "\n",
    "df_fake.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = df.append(df_fake, ignore_index=True)\n",
    "\n",
    "print(df_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(df_comb[['Income', 'CIRatio']], df_comb['Target'])\n",
    "\n",
    "df['pred'] = model.predict_proba(df[['Income', 'CIRatio']])[:,1]\n",
    "df['odds'] = df['pred'] / (1 - df['pred'])\n",
    "\n",
    "df.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['odds']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = ins_feat['Income'], y = ins_feat['Cov_Income_Ratio'], alpha = 0.5, s = df['odds']*100)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Coverage to Income Ratio (Thousands $)')\n",
    "plt.title('Income vs. Coverage to Income Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-priority",
   "metadata": {},
   "source": [
    "### One-Class Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-composer",
   "metadata": {},
   "source": [
    "Lastly, let's look at the support vector machine approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Income': ins_feat['Income'], 'CIRatio': ins_feat['Cov_Income_Ratio']}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "svm = OneClassSVM(gamma=0.00001, nu = 0.05).fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['svm'] = svm\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {-1:'red', 1:'black'}\n",
    "\n",
    "ax.scatter(ins_feat['Income'], ins_feat['Cov_Income_Ratio'], c = df['svm'].map(colors))\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Coverage to Income Ratio (Thousands $)')\n",
    "plt.title('Income vs. Coverage to Income Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Income': ins_feat['Income'], 'CIRatio': ins_feat['Cov_Income_Ratio'], 'Target': 0}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "d_fake = {'Income': np.random.uniform(np.min(ins_feat['Income']), np.max(ins_feat['Income']), size = len(ins_feat['Income'])), \n",
    "          'CIRatio': np.random.uniform(np.min(ins_feat['Cov_Income_Ratio']), np.max(ins_feat['Cov_Income_Ratio']), \n",
    "                                       size = len(ins_feat['Cov_Income_Ratio'])),\n",
    "          'Target': 1}\n",
    "df_fake = pd.DataFrame(data=d_fake)\n",
    "\n",
    "df_comb = df.append(df_fake, ignore_index=True)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(df_comb[['Income', 'CIRatio']], df_comb['Target'])\n",
    "\n",
    "df['pred'] = model.predict_proba(df[['Income', 'CIRatio']])[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
